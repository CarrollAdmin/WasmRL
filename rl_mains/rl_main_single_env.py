from wasm_env import WASMEnv
from gymnasium.envs.registration import register
import gymnasium
from ppo import *
import matplotlib.pyplot as plt
from runtime import *

env_configs = {}
pgm ="test"
env_configs['pgm'] = pgm
env_configs['device'] = 'x86'

register(
	id='WASMEnv-v0',
	entry_point = 'wasm_gym.envs:WASMEnv',
    kwargs={'env_config':env_configs},
    max_episode_steps=3000,
)

num_episodes = 20000  
gamma = 0.9  
actor_lr = 1e-3  
critic_lr = 1e-2  
n_hiddens = 16  
env_name = 'WASMEnv-v0'
return_list = []  
device = torch.device('cuda') if torch.cuda.is_available() \
                             else torch.device('cpu')

env = gymnasium.make(env_name)
n_states = env.observation_space.shape[0]  
n_actions = env.action_space.n  

agent = PPO(n_states=n_states,  
            n_hiddens=n_hiddens,  
            n_actions=n_actions,  
            actor_lr=actor_lr,  
            critic_lr=critic_lr,  
            lmbda = 0.95,  
            epochs = 10, 
            eps = 0.2,  
            gamma=gamma,  
            device = device
            )

# prior knowledge
# prior_pass = []
# for i in range(n_actions):
#     indices=[]
#     exec_time_raw, _ = get_exec_time(env_configs['pgm'], indices, ".")
#     indices.append(i)
#     passes=getPasses(indices)
#     passes_str =" ".join(str(x) for x in passes)
#     print(passes_str)
#     exec_time, _ = get_exec_time(env_configs['pgm'], indices, ".")
#     print("exec_time_raw:", exec_time_raw)
#     print("exec_time:", exec_time)
#     prior_pass.append(exec_time_raw-exec_time)
# print(prior_pass)

# test- prior_pass = [0.003385019302368175, -0.0025716543197631947, 0.0032671451568603294, 0.019552326202392556, -0.003633522987365745, -0.00784749984741212, -0.0034326553344726785, -0.0036132335662841797, -0.01010701656341556, 0.006680870056152366, 0.005216240882873535, 0.00564088821411135, -0.0004458189010619895, 0.003737163543701183, -0.0023335933685302845, -0.003701448440551758, -0.001206207275390614, 0.003706121444702115, 0.0030030488967895397, 0.0023728370666503684, -0.0020787715911865234, 0.0012024164199829213, -0.0044739723205566295, 0.0007253646850585715, -0.0007916212081909291, -0.006319808959960926, 0.01426692008972169, -0.000735330581665028, 0.013023233413696267, -0.01617631912231443, 0.006203174591064453, -0.008884382247924816, 0.004784035682678267, -0.00684561729431149, -0.001183891296386741, -0.01030471324920651, 0.00457453727722168, 0.0007463932037353183, 0.14730715751647952, -0.00895895957946774, 0.0003543138504027987, 0.010948109626770064, 0.0002580404281616322, 0.005017185211181663, 0.00044739246368408203, -0.1668989658355713, 0.0077101707458496205, 0.002594923973083474, 0.0021349668502807506, 0.0046379327774048185, -0.0006786584854125977, -0.004239463806152366, -0.023018765449523915, -0.00130445957183839, -0.03429584503173827, -0.000513410568237338, 0.18721053600311277, 0.002436947822570812, -0.007473778724670366, -0.001599168777465798, -0.0033365964889526256, 0.003597664833068892, -0.005655574798584029, 0.009547901153564409, -0.002360534667968761, -0.0027064800262450728, 0.003531932830810547, -0.00013413429260250576, -0.0023051738739013894, 0.003930163383483842, 0.002641415596008334, -0.022320079803466786, -0.0022135257720947155, -3.452301025391735e-05, 0.0002447843551635631, -0.003852534294128407, -0.0021595716476440763, 0.005689764022827115, 0.01427752971649171, 0.014178657531738303, -0.0001764535903930886, -0.006121206283569325, 0.0040186166763305775, 0.0007003545761108398, 0.002992868423461914, 0.006460809707641624, 0.0106456518173218, 0.0018640995025634988, -0.0013365983963012917, -0.00018360614776613549, -0.003595113754272461, 0.0014902591705321933, 4.5275688171364514e-05, -0.006323790550231911, 0.012178444862365745, 0.0005188703536987416, 0.020612168312072743, -0.0021512269973755216, 0.0035585880279541127, -0.005819368362426802, 0.006119847297668457, -0.012005162239074718, 0.0011262178421020397, 0.14932038784027096, 0.004821205139160123, 0.0031539678573608843, -0.005330896377563454, 0.003062272071838401, -0.012305426597595204, 0.007965564727783203, 0.0011470317840576172, 0.15693519115447999, 0.0068721771240234375, -0.0013060569763183594, -0.007932496070861772, 0.013174557685852073, -0.007576966285705589, 0.006618309020996083, 0.004388666152954135, -0.011611127853393577, -0.0030855178833008035, -0.007542610168457031, -0.0023090124130248912, -0.00481243133544923, 0.008140182495117165, -0.0042994976043701505, 0.004116678237915006, 0.0008659601211547518, -0.0025670528411865234, -0.006522512435913064, 0.008420443534851108, -0.0040880203247070646, 0.0048603296279907116]
# 2mm- prior_pass = [0.03890402317047115, -0.026754355430603005, -0.03389563560485842, 0.010344552993774347, -0.009127616882324219, -0.010702204704284624, 0.0001809835433960183, 0.015560364723205544, 0.020612335205078103, 0.024696087837219216, 0.02392067909240725, 0.012598824501037553, -0.0052172660827636275, -0.018037843704223566, 0.04374208450317385, -0.06451144218444826, 0.012364888191223167, -0.015277266502380371, -0.03562860488891606, 0.0035653829574585627, -0.05097188949584963, 0.04107558727264404, 0.002401185035705522, -0.004376792907714755, 9.465217590265418e-06, -0.00658416748046875, -0.045654916763305686, -0.019809412956237837, 0.07102298736572266, -0.008423352241516135, 0.04485881328582764, 0.010810017585754395, 0.027354097366333097, -0.020597219467163086, -0.01347196102142334, 0.027030110359191895, 0.003064942359924272, -0.0020866870880127397, 0.08436079025268561, -0.039303278923034646, -0.017495894432067893, -0.027548909187316895, 0.0018194675445556419, -0.03827059268951416, -0.00913350582122796, -0.03338999748229987, -0.006244730949401922, 0.03644893169403074, 0.035790109634399436, -0.03254237174987795, -0.015269708633422918, 0.038132643699645974, 0.058611583709716863, -0.01302757263183596, -0.02272930145263674, 0.027211642265319802, 0.034807538986206144, 0.0045666933059692605, 0.015514588356018044, -0.035069489479064964, 0.02925264835357666, 0.0227683305740356, 0.0008818387985228826, -0.017123436927795388, -0.050618100166320845, 0.031223821640014693, -0.017478442192077615, -0.01801309585571287, -0.025819277763366677, 0.0007339239120482954, 0.011803293228149436, 0.05901701450347907, 0.013348293304443315, 0.017075395584106423, -0.01255753040313723, 0.01020271778106685, 0.020799708366394, -0.027768850326538086, 0.016649031639099143, 0.04776356220245359, 0.020491600036621094, 0.013722753524780251, 0.03313016891479492, -0.00504977703094478, 0.03334794044494627, -0.0066658496856689675, -0.03504223823547359, -0.02582693099975586, -0.01610209941864016, 0.03719904422760001, 0.03731648921966546, -0.016230988502502486, -0.004212188720703169, -0.021234774589538596, -0.07125658988952643, -0.0042417764663695845, 0.04135334491729736, 0.019702124595642134, 0.041507601737976074, -0.0035677671432494673, -0.03223009109497066, 0.05068459510803214, 0.01649010181427002, 0.041150784492492654, -0.01038460731506341, 0.02324476242065432, 0.011143279075622625, 0.06331303119659426, -0.046141624450683594, 0.02344813346862784, 0.03601441383361825, 0.06403679847717281, 0.02600781917572026, -0.011605072021484308, -0.002189183235168368, 0.007281851768493719, -0.005679345130920388, -0.041197466850280806, 0.06244637966156008, -0.012221479415893466, -0.0069737672805785245, 0.04744565486907959, -0.015483331680297807, -0.025500226020813033, -0.007309651374816872, 0.021471190452575728, -0.03357250690460212, 0.051130270957946866, 0.023533606529235862, 0.027351784706115767, 0.03230166435241699, -0.03825099468231197, -0.012255024909973211]
# lu- prior_pass = [-0.022940731048583962, -0.0054641485214234065, 0.031509661674499534, 0.00204279422760012, -0.022534823417663552, -0.03819584846496582, -0.028802561759948775, 0.013974213600158714, -0.006460237503051802, -0.003895998001098633, 0.020383930206298806, -0.005886149406433061, 0.033585095405578635, 0.014706540107727095, -0.003566217422485418, 0.01787123680114744, 0.010945320129394531, 0.04081990718841544, -0.019349551200866788, 0.03174946308135984, 0.006042194366455145, 0.020409917831420876, 0.0328624486923218, 0.000453615188598655, -0.03934569358825679, -0.005341100692748957, -0.01948051452636712, -0.0034548282623291238, 0.13168733119964604, 0.009946274757385298, -0.029895329475402854, -0.0006325244903564453, -0.006547737121581965, -0.006516623497009322, 0.0033941268920898438, 0.0008069276809692383, -0.019054293632507324, 0.012603735923767068, 0.1836327314376831, -0.016804647445678667, 0.016368532180786155, 0.0004312276840210405, 0.001980900764465332, -0.0037487983703613503, 0.013167166709899814, -0.03486747741699214, 0.015887784957885787, -0.012392520904541016, 0.0014362573623657449, -0.016729807853698708, 0.0021195888519287553, 0.022433471679687456, 0.04490220546722412, 0.03585431575775144, 0.010019469261169478, 0.013273859024047874, 0.1756888389587402, -8.118152618408203e-05, 0.04467074871063226, -0.0034906864166259766, -0.016171503067016535, -0.004259037971496515, 0.06929275989532468, -0.015541696548461936, -0.013410854339599654, 0.02121932506561275, 0.003124642372131281, 0.013485836982727095, 0.019968533515930198, 0.010787892341613814, -0.04073646068573, -0.0013029336929321067, 0.00030035972595210403, -0.016554713249206543, 0.03215174674987786, 0.024539375305175803, -0.005962276458740257, 0.015279841423034624, -0.037023830413818404, 0.020532059669494673, -0.023969483375549272, 0.00905256271362298, -0.009712266921997115, -0.03076822757720954, -0.01367585659027104, 0.020975160598754927, 0.01145923137664795, -0.026228117942809992, -0.024684715270996138, 0.03822069168090825, -0.013718247413635254, -0.01962513923645015, 0.000897192955017112, 0.02576169967651365, 0.051433992385864324, -0.0077394485473633035, 0.09781842231750487, -0.016858506202697687, 0.032593393325805686, 0.04134910106658929, 0.001219296455383323, -0.006027030944824152, -0.00809302330017081, 0.1833425760269165, -0.02492413520812986, 0.016523218154907204, 0.00892407894134517, -0.013644933700561523, -0.019224143028259255, -0.034919571876525946, 0.010213804244995073, 0.1788092136383057, 0.0008776664733887163, -0.012117981910705566, -0.02253036499023431, -0.008209204673767179, 0.004376268386840909, 0.013564920425415128, 0.044214153289794944, 0.0031605482101439986, 0.02910692691802974, 0.019733834266662642, -0.007429885864257746, 0.014162492752075151, -0.012526202201843195, 0.018944525718688987, -0.01564235687255855, 0.007570719718933083, -0.0060284614562988725, 0.0023047924041748047, 0.0175825595855712, -0.014861989021301203, 0.014614725112915061]
prior_pass = [-0.0003596941630046313, -0.003231684366861942, -0.015832821528116825, -0.017052412033081055, -0.011675039927164788, 0.015239715576171875, -0.006227095921834236, 0.032680511474609375, -0.006773869196573967, 0.07030582427978516, 0.045390288035074944, -0.004891077677408817, -0.013988574345906613, -0.022820313771565792, -0.004477024078369141, 0.0020542939503988, -0.010973374048868778, 0.0028673807779947547, 0.010656038920084598, 0.011953274408976311, 0.010025978088378906, -0.008820772171020508, 0.004126230875651116, 0.005440711975097656, 0.0005997021993001672, -0.00968313217163086, 0.004251956939697266, -0.00803518295288086, 0.27995228767395025, 0.08885463078816735, 0.0037172635396321985, 0.008105357487996345, 0.004126469294230217, -0.0004039605458576734, -0.0039824644724527625, 0.012040376663208008, -0.019926627477010128, 0.005399465560913086, 0.13988431294759118, -0.012076298395792606, -0.0020631949106851843, -0.00620214144388842, 0.002288023630777958, 0.008981704711914062, -0.020562489827473884, -0.008109331130981445, -0.014685074488321903, 0.0010349750518798828, 0.012952009836832645, -0.006619373957316044, -0.0042722225189208984, 0.008471488952636719, -0.04273835817972815, 0.0003604888916015625, 0.008989175160725837, 0.007352352142333984, 0.26919714609781903, 0.005484898885091072, 0.017577330271402958, -0.018384456634521484, -0.0066452821095783765, 0.003644386927286747, -0.01325082778930664, 0.011286894480387333, -0.0015362103780109937, -0.017739375432332394, -0.0013987223307291297, -0.00567936897277832, 0.007071415583292606, -0.001079241434733147, 0.0006660620371500281, 0.007562398910522461, -0.0068074862162271765, 0.001451253890991211, 0.002558310826619503, -0.006379842758178711, -0.00638270378112793, 0.00026535987854003906, -0.0010190804799398157, 0.008749643961588505, 0.004486878712972042, 0.0020938714345295484, -0.02221822738647461, 0.009421269098917606, 0.005587100982666016, -0.01893758773803711, 0.009273608525594113, 0.00030883153279614994, -0.017321983973185184, 0.005923906962076786, -0.009956121444702148, -0.010936816533406613, 0.013598521550496456, -0.012684186299641853, -0.0022962093353271484, -0.021881103515625, 0.23056228955586755, -0.011358420054117913, 0.011668125788370731, -0.0220585664113363, 0.009610573450724247, 0.0022734800974528735, -0.0023822784423828125, 0.21657776832580566, 0.0057068665822347375, -0.009531418482462528, -0.002690871556599972, 0.0052756468454997485, 0.0014312267303466797, 0.0041216214497884485, -0.005509614944458008, 0.20858049392700195, 0.005481402079264397, -0.009798526763916016, 0.010159969329833984, 0.003341833750406975, -0.007170279820760017, -0.011926015218098995, -0.010537226994832394, -0.009489456812540653, -0.007132291793823242, 0.027020374933878655, -0.014472246170043945, -0.006873766581217411, -0.019937753677368164, -0.09763010342915845, 0.0011192957560222094, -0.00043876965840661253, -0.001997232437133789, 0.0008194446563720703, 0.028395096460978153, -0.013383626937866211, 0.013196547826131222]

rewards_mean = []
for i in range(num_episodes):
    
    state = env.reset() 
    done = False  
    episode_return = 0  
 
    transition_dict = {
        'states': [],
        'actions': [],
        'next_states': [],
        'rewards': [],
        'dones': [],
    }
    pre_gain = []
    while not done:
        action = agent.take_action(state)  
        next_state, reward, done, _, _  = env.step(action)  
        transition_dict['states'].append(state)
        transition_dict['actions'].append(action)
        transition_dict['next_states'].append(next_state)
        transition_dict['rewards'].append(reward)
        transition_dict['dones'].append(done)
        pre_gain.append(prior_pass[action])
        
        state = next_state
        
        episode_return += reward
 
    # reward alloc
    for k in range(len(transition_dict['rewards'])):
        pass_iter = transition_dict['actions'][k]
        # print(pass_iter,prior_pass[pass_iter], pre_gain[k], episode_return, prior_pass[pass_iter]/sum(pre_gain), prior_pass[pass_iter]/sum(pre_gain)*episode_return  )
        transition_dict['rewards'][k] = pre_gain[k]/sum(pre_gain)*episode_return 

    return_list.append(episode_return)
    
    agent.learn(transition_dict)
 
    # plt reward
    rewards_mean.append(np.mean(return_list[-10:]))
    column_name = 'episode_reward_mean'
    plt.plot(rewards_mean)
    plt.xlabel('Episodes')
    plt.ylabel(column_name)
    plt.title('Reward Progress')
    plt.grid(True)
    plt.savefig('results/reward_plot-'+pgm+'.png')
    plt.close()
    
    print(f'iter:{i}, return:{np.mean(return_list[-10:])}')
    output = ""
    output += f"{i}: {np.mean(return_list[-10:])}\n"
    with open('results/reward-'+pgm+'.txt', 'a') as file:
        file.write(output)


